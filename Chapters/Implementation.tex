% !tex root = ../Thesis.tex

This chapter describes the design, module implemetation and final implemetations
of the pitch correction system. The implementation code was written in Octave, a
free and open source alternative to Matlab. Some important, short code-snips are
shown and explaind to give deeper insight into the details of the implementation.

Since one of the goals of this report is to compare the performance of the pitch
corrector when using different modules, the evaluation metrics used are described
first. Theses metrics are described first to reflect the fact that the metrics
were designed before the structure and submodules were implemented in an effort to
minimise biased results. Once these metrics are well understood, the desing and
implementation of the pitch corrector and its submodules are described.

\section{Evaluation Metrics Design}

The goal of using metrics is to give a meaningful quantitative way of measuring
the success of the pitch corrector. It provides way to compare the performance of
different sub modules and choose the configuration that produces the best result.
Since the ultimate goal of an audio pitch corrector is to produce better sounding
music, the most rigorous way to judge the effectiveness of the pitch corrector
would be to run a psychological survey on which combination of sub modules sound
best. This is beyond the scope of this project. Instead, some simplifications are
made and metrics are designed based on the research done on music theory. These
metrics act as a proxy for the results given by a physiological survey and are
much easier and cheaper to run. Two aspects of the pitch corrector are chosen to
be assessed. The effectiveness of it and the noise or distortion of the audio
signal introduced by the pitch corrector.

\subsection{Pitch Corrector Metrics}

The effectiveness metric is a way of measuring how much the pitch corrector
corrects the pitch. This metric will answer the question of how in tune the audio
is before and after the correction is applied and produce a number indicating the
improvement. The algorithm to achieve this will make use of the frequency contour
function. This is a function of the fundamental frequency of a signal over time.
Exactly how the frequency contour is extracted from the signal will be discussed
in the ``Pitch Correction Design'' section. From this frequency contour function,
it is possible to find the closest correct frequency to this function as shown in
listing \ref{lst:getClosestFreqContour}.\octavelisting{getClosestFreqContour} The
exact details of how the correct frequencies are calculated will be explained in
the ``Choosing Wanted Frequency'' section. Listing \ref{lst:getClosestFreqContour}
shows how the closest frequency contour is calculated.

Once the closest frequency contour is found, both are converted into a pitch
contour by taking the $log_2$ of the functions. This is done because using
frequency contours would eventually weigh the importance of the higher frequencies
more than the lower frequencies. A plot of these two contours would allow one to
see the intonation error as shown in figure \ref{fig:ErrorFunction}.

\begin{figure}[h]
	\includegraphics[width=\textwidth,trim={3.5cm 0cm 2.8cm 0cm}]
	{IntonationError}
	\caption{Illustration of Intonation Errors in a Pitch Contour Diagram}
	\label{fig:ErrorFunction}
\end{figure}

The red regions in figure \ref{fig:ErrorFunction} are intonation errors. To be
perfectly in tune would be saying there are no red regions, or equivalently, the
error function is zero everywhere. Therefore the smaller the red regions are the
better the pitch corrector. A common metric to measure this is the mean square
error metric and even has a built-in function in Octave. Therefore the mean square
error would indicate how in tune the audio recording is, weighing larger
intonation errors greater than small intonation errors. This metric is referred to
as the mean squared pitch error and can fundamentally not be greater than
$1.736\times10^{-3}$ in the equal tempered tuning system. How this number is
calculated is shown in equation \ref{eq:MaxIntonationError} and is essentially
half the distance between two notes in the logarithmic pitch scale.

\begin{equation}\label{eq:MaxIntonationError}
	\bigg(\frac{1}{2}log_2(\sqrt[12]{2}) - log_2(1)\bigg)^2 \approx
	1.736\times10^{-3}
\end{equation}

To formalise this metric algorithm, a standard recording needs to be chosen to
test with. An exponential chirp signal is chosen, starting at 110Hz, ending at
440Hz and lasting 5 seconds. Figure \ref{fig:ChirpContour} shows the pitch contour
of the signal with the closest correct pitch contour. This signal has a mean
squared pitch error of $0.59 \times 10^{-3}$. The algorithm will measure the
mean squared pitch error after the pitch correction is applied and return a ratio
of the original and corrected mean squared pitch error. The idea being that the
metric essentially says the pitch correction effect causes the recording to be X
times more in tune. The goal of the pitch corrector is to maximise this metric.

\begin{figure}[h]
	\includegraphics[width=\textwidth,trim={3.5cm 0cm 2.8cm 0cm}]
	{ChirpContour}
	\caption{Exponential Chirp Contour with Closest Frequency Contour}
	\label{fig:ChirpContour}
\end{figure}

The effectiveness metric unfortunately relies on the frequency detector to be
absolutely correct. This is because it depends on the results of the frequency
contour before and after the correction was made. The choice to use a clean chirp
signal for this metric was made to minimise dependence on the frequency detector.

Now that the effectiveness of the pitch corrector can be measured, a distortion
metric needs to be designed to measure how much the pitch corrector distorts the
signal unnecessarily. The idea is to have a signal in a state that it shouldn't
require a correction anymore, i.e. Already pitch corrected, and then apply the
pitch correction effect and see how much the signal change. The idea is to measure
the peak of the autocorrelation of a signal after applying the pitch correction
effect. This is the baseline value. Then apply the pitch correction effect again
and calculate the maximum value of the cross-correlation between the signal before
and after the second pitch correction effect has been applied. The ratio between
the maximum cross-correlation value and the baseline value gives in indication to
how much the pitch corrector distorts the signal unnecessarily. This ratio is
called the distortion metric, measured as a percentage. A pitch correction
algorithm will attempt to produce the highest similarity ratio, 100\% being a
perfect score. Listing \ref{lst:distortionMetric} shows the distortion metric
algorithm implemented in Octave.

\octavelisting{distortionMetric}

The testing recording for the distortion metric is chosen to be the same as the
one for the effectiveness metric except for one thing. The distortion signal needs
some added white noise to have the distortion in the whole frequency range
accounted for. To avoid the white noise from interfering with the frequency
detector, the level is set to \color{red}XX\color{black}db since both the
detectors are shown to be robust enough to that level of noise in the next
section.

\subsection{Noise Robustness Metric}

As has already been mentioned, the effectiveness metric relies on the fact that
the frequency detector is absolutely correct. To give some sense that the
frequency detector is capable of producing valid results, a metric is designed to
measure how much noise the frequency detector can deal with before producing
unacceptable results. Unacceptable results are seen as a mean square error of more
than $0.59 \times 10^{-6}$, i.e. three orders of magnitude greater than the mean
squared error of the testing signal in figure \ref{fig:ChirpContour}. The testing
signal will be the  same as the one in figure 3.2 since the exact pitch contour of
the signal is known. The metric will produce a db level of noise that can be added
before the unacceptable mean squared error value has been reached. The goal of the
pitch detector would be to maximise this db level of noise added.

\section{Pitch Corrector Design}

The design of the pitch corrector is guided by what was found in the literature
review. Specifically the ``General Pitch Correction Structure'' section was found
useful. All of pitch correctors investigated had a modular design that included a
frequency detector and a frequency scaler. Some extra modules, unique to a
specific pitch corrector, were mostly ignored in the pursuit of simplicity. The
``pitch manipulation'' and ``target pitch'' modules represents essentially the
same function and was named the ``choosing wanted frequency'' module.

This chapter describes the general structure of the pitch corrector first,
explaining how the data flows through the pitch corrector. Thereafter the concept
of segmentation is explained and the exact details of how the pitch contour is
calculated is laid out. Next the interface between different modules are
designed, giving a detailed description of what each module should accept and
produce.

\subsection{Structure}

The overall structure of the pitch corrector can be represented in a flow diagram.
This structure is shown in figure \ref{fig:PitchCorrectorFlowDiagram}. The blocks
represent modules that receives inputs and produces outputs. The arrows represents
the data and is labeled according to what kind of data it is, pointing in the
direction the data flows. The overall structure receives untuned audio and
produces tuned audio.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{PitchCorrectorFlowDiagram}
\caption{Flow Diagram of Pitch Corrector}
\label{fig:PitchCorrectorFlowDiagram}
\end{figure}

\lstset{language=Octave}

The Octave code of the structure seen in figure
\ref{fig:PitchCorrectorFlowDiagram} can be seen in listing
\ref{lst:getCorrectedPitch}. From this code, it can be seen that some extra
information, other than that provided by the arrows, are needed. This information
includes the sampling frequency, the segment size and the hop size and is needed
by each module to function correctly. The sampling frequency is self explanatory
but segment size and hop size relates to the concept of segmentation, not yet
explained. This extends naturally to the idea of a frequency contour and is why
the wrapper function \colorbox{backcolour}{\lstinline{getFrequencyContour}}
exists, providing an intermediate step to the frequency detection module.

\octavelisting{getCorrectedPitch}

Segmentation is a concept required by the structure of the pitch corrector. It
essentially involves breaking up the input signal into segments, and doing
computations on these individual segments. The frequency detector and frequency
scaler performs it's operation in the context of a single segment. The idea of
segmentation can be seen in figure \ref{fig:Segmentation}. The figure shows a
signal being segmented into chunks of 2 048 samples and a 50\% overlap. This
corresponds to a segment duration of around 46ms, assuming a sampling rate of 44
100 samples per second.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth, trim={2.5cm 0cm 2.5cm 0cm},clip]
{SegmentationVisualization}
\caption{Segmentation Visualization}
\label{fig:Segmentation}
\end{figure}

There is an obvious trade-off when considering the overlapping percentage. The
more the signal overlaps, the more computational power is needed but it does
usually provide more gradual changes when stitching segments back together. For
this implementation, the overlap percentage was chosen at whatever was most
natural for the pitch shifter(50\% for simple overlap and add and 75\% for the
phase vocoder). A less obvious trade-off is that of segment size. The larger the
segment size, the more latency the system will have but will increase the
fundamental resolution in frequency for the frequency detection and frequency
scaling modules.  Practically the pitch detectors needs al least 2 periods to
calculate the frequency properly, meaning the segment size needs to be at least 1
764 samples long. This corresponds to two periods of a 50Hz signal at 44 100
samples per second. Listing \ref{lst:segment} shows how these segments are
obtained.

\octavelisting{segment}

From this array of segments, it is possible to create the frequency contour. The
basic idea is to pass each segment into the frequency detector, producing a list
of frequencies over time. Unfortunately implementing exactly this would produce
erratic results. The problem comes in when the specified segment is an unvoiced
one. This means no instrument is producing sound in that frame and the frequency
detector will find a frequency based on the background noise. This has been found
to be very high values and can cause issues in the frequency scaler later on. This
is unwanted behaviour and a mechanism is built in to allow the frequency detector
to simply hold the frequency of the previous segment if it regards the segment as
unvoiced. This produces a frequency contour that's much easier to work with.
Listing \ref{lst:getFrequencyContour} shows the Octave implementation of how this
is achieved.

\octavelisting{getFrequencyContour}

It can be seen that a pre-filter is needed for the frequency detector. The filter
is applied in the \colorbox{backcolour}{\lstinline{getFrequencyContour}} function
to allow the frequency detector to only consider individual segments, essentially
allowing for more elegant code. This pre-filter is specific to the frequency
detector and will be discussed more in the frequency detector section.

\color{red}
To do:
\begin{itemize}
	\item Pitch contour explanation
	\item Pitch contour listing
\end{itemize}
\color{black}

\subsection{Interface}

\color{red}
To do:
\begin{itemize}
	\item Interface philosophy
	\item Frequency detectors and scalers should be swappable
\end{itemize}
\color{black}

\section{Choosing Wanted Frequency}

\color{red}
To do:
\begin{itemize}
	\item Describe why choosing wanted frequency is not trivial
	\item Naive approach
	\begin{itemize}
		\item Describe approach
		\item Show results of approach
	\end{itemize}
	\item Schmitt Trigger Approach
	\begin{itemize}
		\item Describe approach
		\item Show results of approach
	\end{itemize}
	\item Evaluation Metric
	\begin{itemize}
		\item Describe metric
		\item Show why Schmitt trigger is better
	\end{itemize}
\end{itemize}
\color{black}

\section{Frequency Detector}

\color{red}
To do:
\begin{itemize}
	\item Explain that this is the basis for the frequency scaler
	\item Explain other things
\end{itemize}
\color{black}

\subsection{Zero Crossing Method}

\color{red}
To do:
\begin{itemize}
	\item Describe method in more detail than lit review
	\item Show snips of code and graphically what it's doing
	\item Show performance metrics
\end{itemize}
\color{black}

\subsection{Autocorrelation Method}

\color{red}
To do:
\begin{itemize}
	\item Describe method in more detail than lit review
	\item Show snips of code and graphically what it's doing
	\item Show performance metrics
\end{itemize}
\color{black}

\section{Frequency Scaler}

\color{red}
To do:
\begin{itemize}
	\item Explain time vs frequency approaches
	\item Explain other things
\end{itemize}
\color{black}

\subsection{Phase Vocoder}

\color{red}
To do:
\begin{itemize}
	\item Describe method in more detail than lit review
	\item Show snips of code and graphically what it's doing
	\item Show performance metrics
\end{itemize}
\color{black}

\subsection{Simple Overlap and Add}

\color{red}
To do:
\begin{itemize}
	\item Describe method in more detail than lit review
	\item Show snips of code and graphically what it's doing
	\item Show performance metrics
\end{itemize}
\color{black}

\section{Pitch Corrector}

\color{red}
To do:
\begin{itemize}
	\item Describe which modules were added put together
	\item Describe why each module was chosen
	\item Describe each system and show its performance
\end{itemize}
\color{black}

\section{Concept Expansion}

\color{red}
To do:
\begin{itemize}
	\item Explain that more cool stuff were found
	\item Post Correction
	\item Harmonization
	\item Pitch Scaling by a Constant Factor
\end{itemize}
\color{black}
